{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85cb2b29-0a37-4949-ac88-6ec671cb0363",
   "metadata": {},
   "source": [
    "# Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75848699",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import time\n",
    "from scipy import signal\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0faa4ca-74c1-4d38-b8a1-51b1348c6350",
   "metadata": {},
   "source": [
    "# Functions for filtering the signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d6ccd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtering(data,fs,lowerCutoff=1, higherCutoff=3, filterOrder=5):\n",
    "    lowerCutoffDigital = lowerCutoff / (0.5 * fs)\n",
    "    higherCutoffDigital = higherCutoff / (0.5 * fs)\n",
    "    b, a = signal.butter(filterOrder, [lowerCutoffDigital, higherCutoffDigital], btype='band', analog=False)\n",
    "    filtsignal = signal.filtfilt(b, a, data)\n",
    "    return filtsignal\n",
    "def bandpass_filter(data,fps, lowcut, highcut):\n",
    "    fs = fps # Частота дискретизации (количество измерений сигнала в 1 сек)\n",
    "    nyq = 0.5 * fs # Частота Найквиста\n",
    "    low = float(lowcut) / float(nyq)\n",
    "    high = float(highcut) / float(nyq)\n",
    "    order = 6.0 # Номер фильтра в scipy.signal.butter\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    bandpass = lfilter(b, a, data)\n",
    "    return bandpass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a751054-cad6-4415-b239-1777d5b8f1bb",
   "metadata": {},
   "source": [
    "# Function for finding the heart rate of a rPPG Signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db5e7d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def HR_FINDER(wave,fs):\n",
    "    fftData = np.fft.fft(wave,1000)[0:500]\n",
    "    hz=np.linspace(0,fs/2,int(len(fftData)))\n",
    "    powerSpectrum = np.abs(fftData)**2\n",
    "    maxFreq = np.argmax(powerSpectrum)\n",
    "    HR=hz[maxFreq]*60\n",
    "    return HR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27e99638",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fft_wave(wave):\n",
    "    fftData = np.fft.fft(wave,1000)[0:500]\n",
    "    powerSpectrum = np.abs(fftData)**2\n",
    "    return powerSpectrum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12237fc2-30c1-4bc3-a071-c090fe20c203",
   "metadata": {},
   "source": [
    "# Function for face Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43e21fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#img=cv2.imread(r\"C:\\Users\\Lenovo\\Pictures\\Camera Roll\\WIN_20220519_14_51_19_\")\n",
    "#img = cv2.imread(r\"C:\\Users\\Lenovo\\Pictures\\Camera Roll\\WIN_20220520_20_11_49_Pro.jpg\")\n",
    "# img = cv2.imread(r\"C:\\Users\\Lenovo\\Pictures\\Camera Roll\\WIN_20220520_20_16_00_Pro.jpg\")\n",
    "#v=cv2.VideoCapture(r\"C:\\Users\\Lenovo\\Desktop\\Camera Roll\\WIN_20220325_17_44_26_Pro.mp4\")\n",
    "mpDraw = mp.solutions.drawing_utils\n",
    "mpFaceMesh = mp.solutions.face_mesh\n",
    "faceMesh = mpFaceMesh.FaceMesh(max_num_faces=2,min_detection_confidence=0.5)\n",
    "drawSpec = mpDraw.DrawingSpec(thickness=1, circle_radius=2,color=(0,128,0))\n",
    "def masking(img):\n",
    "    imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    results = faceMesh.process(imgRGB)\n",
    "    pTime=0\n",
    "    face=[]\n",
    "    num1=[67,109,10,338,104,69,108,151,337,299]\n",
    "    num2=[66,280,425,426,266,50,205,147,187,207,432,138]\n",
    "    facenum=[21,54,143,67,149,14,338,297,332,284,251,389,356,454,323,361,288,397,365,379,378,400,377,152,148,176,149,150,136,172\n",
    "            ,58,132,43,234,127,162]\n",
    "    facecont=[]\n",
    "    faceadj=[33,21,3,11,29,1]\n",
    "    left=[]\n",
    "    right=[]\n",
    "    if results.multi_face_landmarks:\n",
    "        landmarkz=results.multi_face_landmarks[0]\n",
    "        for faceLms in results.multi_face_landmarks:\n",
    "            #mpDraw.draw_landmarks(img, faceLms, mpFaceMesh.FACEMESH_CONTOURS,\n",
    "                                      #drawSpec,drawSpec)\n",
    "            #print(frame.shape)\n",
    "            for id,lm in enumerate(faceLms.landmark):\n",
    "                ih, iw, ic = img.shape\n",
    "                x,y = int(lm.x*iw), int(lm.y*ih)\n",
    "                #cv2.putText(img,str(id),(x,y),cv2.FONT_HERSHEY_PLAIN,.5,(0,0,255),1)\n",
    "                face.append((x,y))\n",
    "                if id in facenum:\n",
    "                    facecont.append([x,y])\n",
    "                if id ==107 or id==55:\n",
    "                    right.append((x,y))\n",
    "                if id ==336 or id==285:\n",
    "                    left.append((x,y))\n",
    "                #if id in num1:\n",
    "                    #cv2.rectangle(img,(face[id][0]-40,face[id][1]-40),(face[id][0]+40,face[id][1]+40),(255,0,0),3)\n",
    "                #if id in num2:\n",
    "                #cv2.rectangle(img,(face[id][0]-20,face[id][1]-40),(face[id][0]+20,face[id][1]+40),(255,0,0),3)\n",
    "\n",
    "        ###################################### face_oval#######################################################\n",
    "        blobs=[]\n",
    "        l = []\n",
    "        i=0\n",
    "        for source_id,target_id in mpFaceMesh.FACEMESH_FACE_OVAL:\n",
    "            if i in faceadj:\n",
    "                source=landmarkz.landmark[source_id]\n",
    "                real_source=(int(source.x*img.shape[1]),int(source.y*img.shape[0]))\n",
    "                l.append([(int(source.x*img.shape[1])),int(source.y*img.shape[0]-20)])\n",
    "                blobs.append(l)\n",
    "            else:\n",
    "                source=landmarkz.landmark[source_id]\n",
    "                real_source=(int(source.x*img.shape[1]),int(source.y*img.shape[0]))\n",
    "                l.append([(int(source.x*img.shape[1])),int(source.y*img.shape[0])])\n",
    "                blobs.append(l)\n",
    "            i+=1\n",
    "        coords = blobs[0]\n",
    "        for i in range(0,2):\n",
    "            coords.append([left[i][0],left[i][1]])\n",
    "        req_coord_lefteyebrow=[4,0,2,7,1,6,5,3,8,9]\n",
    "        sel_coords = []\n",
    "\n",
    "        # req_coords = [11,27,9,22,7,28,24,14,6,0,15,5,26,35,19,33,2]\n",
    "        req_coords = [11,29,1,27,13,9,12,4,22,17,7,31,28,23,24,34,14,16,6,25,0,30,2,15,20,5,10,26,32,35,8,19,18,33,21,3]\n",
    "        for i in req_coords:\n",
    "            sel_coords.append(coords[i])\n",
    "        mas = np.zeros((img.shape[0],img.shape[1],3),dtype=np.uint8)\n",
    "        cv2.fillPoly(mas, pts=[np.asarray(sel_coords)], color=(255,255,255))\n",
    "        masked = cv2.bitwise_and(img, mas)\n",
    "\n",
    "        ######################################LIPS###############################################################\n",
    "        blobs=[]\n",
    "        l = []\n",
    "        i=0\n",
    "        \n",
    "        for source_id,target_id in mpFaceMesh.FACEMESH_LIPS:\n",
    "            source=landmarkz.landmark[source_id]\n",
    "            target=landmarkz.landmark[target_id]\n",
    "            real_source=(int(source.x*img.shape[1]),int(source.y*img.shape[0]))\n",
    "            real_target=(int(target.x*img.shape[1]),int(target.y*img.shape[0]))\n",
    "            l.append([(int(source.x*img.shape[1])),int(source.y*img.shape[0])])\n",
    "            blobs.append(l)\n",
    "        coords = blobs[0]\n",
    "        sel_coords = []\n",
    "        # req_coords = [11,27,9,22,7,28,24,14,6,0,15,5,26,35,19,33,2]\n",
    "        req_coords = [11,29,1,27,13,9,12,4,22,17,7,31,28,23,24,34,14,16,6,25,0,30,2,15,20,5,10,26,32,35,8,19,18,33,21,3]\n",
    "        req_coord_eye=[33,32,4,14,18,6,0,26,39,7,23,16,11,5,38,3,27,22]\n",
    "        for i in req_coord_eye:\n",
    "            sel_coords.append(coords[i])\n",
    "        mas = np.zeros((img.shape[0],img.shape[1],3),dtype=np.uint8)\n",
    "        cv2.fillPoly(mas, pts=[np.asarray(sel_coords)], color=(255,255,255))\n",
    "        masked1 = cv2.bitwise_and(masked, mas)\n",
    "        lip=cv2.subtract(masked,masked1)\n",
    "        ################################lefteye####################################################################\n",
    "        blobs=[]\n",
    "        l = []\n",
    "        i=0\n",
    "        for source_id,target_id in mpFaceMesh.FACEMESH_LEFT_EYE:\n",
    "            source=landmarkz.landmark[source_id]\n",
    "            target=landmarkz.landmark[target_id]\n",
    "            real_source=(int(source.x*img.shape[1]),int(source.y*img.shape[0]))\n",
    "            real_target=(int(target.x*img.shape[1]),int(target.y*img.shape[0]))\n",
    "            l.append([(int(source.x*img.shape[1])),int(source.y*img.shape[0])])\n",
    "            blobs.append(l)\n",
    "        coords = blobs[0]\n",
    "        sel_coords = []\n",
    "        #ctr = np.array(facecont).reshape((-1,1,2)).astype(np.int32)\n",
    "        #cv2.drawContours(img,[ctr],0,(255,255,255),1)\n",
    "        req_coord_lefteye=[3,10,6,5,12,4,0,13,7,8]\n",
    "        for i in req_coord_lefteye:\n",
    "            sel_coords.append(coords[i])\n",
    "        mas = np.zeros((img.shape[0],img.shape[1],3),dtype=np.uint8)\n",
    "        cv2.fillPoly(mas, pts=[np.asarray(sel_coords)], color=(255,255,255))\n",
    "        masked2 = cv2.bitwise_and(lip, mas)\n",
    "        lefteye=cv2.subtract(lip,masked2)\n",
    "        ###############################################righteye#############################################################\n",
    "        blobs=[]\n",
    "        l = []\n",
    "        i=0\n",
    "        for source_id,target_id in mpFaceMesh.FACEMESH_RIGHT_EYE:\n",
    "            source=landmarkz.landmark[source_id]\n",
    "            target=landmarkz.landmark[target_id]\n",
    "            real_source=(int(source.x*img.shape[1]),int(source.y*img.shape[0]))\n",
    "            real_target=(int(target.x*img.shape[1]),int(target.y*img.shape[0]))\n",
    "            l.append([(int(source.x*img.shape[1])),int(source.y*img.shape[0])])\n",
    "            blobs.append(l)\n",
    "        coords = blobs[0]\n",
    "        sel_coords = []\n",
    "        req_coord_righteye=[1,2,3,6,11,5,0,8,4,7,9,12]\n",
    "        for i in req_coord_righteye:\n",
    "            sel_coords.append(coords[i])\n",
    "        mas = np.zeros((img.shape[0],img.shape[1],3),dtype=np.uint8)\n",
    "        cv2.fillPoly(mas, pts=[np.asarray(sel_coords)], color=(255,255,255))\n",
    "        masked2 = cv2.bitwise_and(lefteye, mas)\n",
    "        righteye=cv2.subtract(lefteye,masked2)\n",
    "        ##################################################lefteyebrow############################################################\n",
    "        blobs=[]\n",
    "        l = []\n",
    "        i=0\n",
    "        for source_id,target_id in mpFaceMesh.FACEMESH_LEFT_EYEBROW:\n",
    "            source=landmarkz.landmark[source_id]\n",
    "            target=landmarkz.landmark[target_id]\n",
    "            real_source=(int(source.x*img.shape[1]),int(source.y*img.shape[0]))\n",
    "            real_target=(int(target.x*img.shape[1]),int(target.y*img.shape[0]))\n",
    "            l.append([(int(source.x*img.shape[1])),int(source.y*img.shape[0])])\n",
    "            blobs.append(l)\n",
    "        coords = blobs[0]\n",
    "        for i in range(0,2):\n",
    "            coords.append([left[i][0],left[i][1]])\n",
    "        sel_coords = []\n",
    "        req_coord_lefteyebrow=[4,0,2,7,1,6,5,3,8,9]\n",
    "        for i in req_coord_lefteyebrow:\n",
    "            sel_coords.append(coords[i])\n",
    "        mas = np.zeros((img.shape[0],img.shape[1],3),dtype=np.uint8)\n",
    "        cv2.fillPoly(mas, pts=[np.asarray(sel_coords)], color=(255,255,255))\n",
    "        masked3 = cv2.bitwise_and(righteye, mas)\n",
    "        lefteyebrow=cv2.subtract(righteye,masked3)\n",
    "        ##################################################righteyebrow#####################################################3\n",
    "        blobs=[]\n",
    "        l = []\n",
    "        i=0\n",
    "        for source_id,target_id in mpFaceMesh.FACEMESH_RIGHT_EYEBROW:\n",
    "            source=landmarkz.landmark[source_id]\n",
    "            target=landmarkz.landmark[target_id]\n",
    "            real_source=(int(source.x*img.shape[1]),int(source.y*img.shape[0]))\n",
    "            real_target=(int(target.x*img.shape[1]),int(target.y*img.shape[0]))\n",
    "            l.append([(int(source.x*img.shape[1])),int(source.y*img.shape[0])])\n",
    "            blobs.append(l)\n",
    "        coords = blobs[0]\n",
    "        for i in range(0,2):\n",
    "            coords.append([right[i][0],right[i][1]])\n",
    "        sel_coords = []\n",
    "        req_coord_righteyebrow=[5,4,7,1,9,8,6,2,3,0]\n",
    "        for i in req_coord_righteyebrow:\n",
    "            sel_coords.append(coords[i])\n",
    "        mas = np.zeros((img.shape[0],img.shape[1],3),dtype=np.uint8)\n",
    "        cv2.fillPoly(mas, pts=[np.asarray(sel_coords)], color=(255,255,255))\n",
    "        masked4 = cv2.bitwise_and(lefteyebrow, mas)\n",
    "        righteyebrow=cv2.subtract(lefteyebrow,masked4)\n",
    "    #################################################################################################################3\n",
    "        cTime = time.time()\n",
    "        fps = 1 / (cTime - pTime)\n",
    "        pTime = cTime\n",
    "        return righteyebrow\n",
    "    else:\n",
    "        return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db88f7c-d6cc-4ed4-a116-177f6772e1b4",
   "metadata": {},
   "source": [
    "# Preprocessing of the spatially averged 1d-signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3bad7d9a-f1f8-49ae-a04f-4297c293de43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RAW(matrix):\n",
    "    green_matrix=[]\n",
    "    for z in range(matrix.shape[0]):\n",
    "        for i in range(3):\n",
    "            green=matrix[z,:,i]\n",
    "            greend=scipy.signal.detrend(green) ####detrending\n",
    "            greenN=greend/np.std(greend)\n",
    "            greenf=filtering(greenN,fs,.7,3)#### filtering\n",
    "            greenf=(greenf-greenf.min())/(greenf.max()-greenf.min())\n",
    "            green_matrix.append(greenf)\n",
    "    return np.array(green_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae2d223-7233-4574-a1f5-62ee11123826",
   "metadata": {},
   "source": [
    "# Main code for saving the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a356c282",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path=r'C:\\Users\\PhysioSens\\Desktop\\python-jupyter\\MS-Work-Documentation\\Novel-HR\\Physiosens1D\\data\\val' #### give the path where you want to save the file\n",
    "DATA_path=Path(r'D:\\DL_DATA\\UBFC TEST')#### Data path where the train or test data is \n",
    "#num1=[109,10,338,108,151,337]\n",
    "num1=[10]\n",
    "num2=[50,280]\n",
    "mpFaceMesh = mp.solutions.face_mesh\n",
    "faceMesh = mpFaceMesh.FaceMesh(max_num_faces=1)\n",
    "for sub in os.listdir(DATA_path):\n",
    "    full_path=DATA_path/sub\n",
    "    ext=os.listdir(full_path)\n",
    "    label_path=full_path/ext[0]\n",
    "    vid_path=full_path/ext[1]\n",
    "    vid=cv2.VideoCapture(str(vid_path))\n",
    "    label=np.loadtxt(label_path)\n",
    "    fs=vid.get(cv2.CAP_PROP_FPS)\n",
    "    matrix=np.zeros((len(num1)+len(num2),150,3))\n",
    "    count=0\n",
    "    flag=0\n",
    "    num_sub=0\n",
    "    for i in range(int(vid.get(cv2.CAP_PROP_FRAME_COUNT))):\n",
    "        ret,frame=vid.read()\n",
    "        if ret==False:\n",
    "            break\n",
    "        frame=masking(frame)### you can use this if you want to create a mask to remove non-skin pixel highly recommended\n",
    "        imgRGB = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = faceMesh.process(imgRGB)\n",
    "        if i%150==0 and i!=0:\n",
    "            num_sub+=1\n",
    "            wave=label[0][i-150:i]\n",
    "            wave=scipy.signal.detrend(wave)\n",
    "            wave=(wave-wave.min())/(wave.max()-wave.min())\n",
    "            hr=label[1][i-150:i]\n",
    "            sub_label=(wave,hr)\n",
    "            \n",
    "            green_matrix=RAW(matrix) #### Preprocessing for the raw signals\n",
    "            matrix=np.zeros((len(num1)+len(num2),150,3))\n",
    "            flag,count=0,0\n",
    "\n",
    "\n",
    "            green_vid_path=os.path.join(save_path,'data')\n",
    "            green_label_path=os.path.join(save_path,'label')\n",
    "            os.makedirs(green_vid_path,exist_ok=True)\n",
    "            os.makedirs(green_label_path,exist_ok=True)\n",
    "            np.save(os.path.join(green_vid_path,f'{sub} {num_sub}.npy'),green_matrix)####saving the video data\n",
    "            np.save(os.path.join(green_label_path,f'{sub} {num_sub}.npy'),sub_label)##### saving the ground-truth PPG\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "        if results.multi_face_landmarks:\n",
    "            for faceLms in results.multi_face_landmarks:\n",
    "                face=[]\n",
    "                for id,lm in enumerate(faceLms.landmark):\n",
    "                    ih, iw, ic = frame.shape\n",
    "                    x,y = int(lm.x*iw), int(lm.y*ih)\n",
    "                    face.append((x,y))\n",
    "                    if id in num1:\n",
    "                        #cv2.rectangle(frame,(face[id][0]-60,face[id][1]-25),(face[id][0]+60,face[id][1]+25),(255,0,0),3)\n",
    "                        x=np.mean(frame[face[id][1]-25:face[id][1]+25,face[id][0]-60:face[id][0]+60,2])####Can change the rectangluar corrdinate to\n",
    "                        ###select the ROI\n",
    "                        if x>0 and x<255:\n",
    "                            matrix[flag,count,2]=x\n",
    "                        y=np.mean(frame[face[id][1]-25:face[id][1]+25,face[id][0]-60:face[id][0]+60,1])\n",
    "                        if y>0 and y<255:\n",
    "                            matrix[flag,count,1]=y\n",
    "                        z=np.mean(frame[face[id][1]-25:face[id][1]+25,face[id][0]-60:face[id][0]+60,0])\n",
    "                        if z>0 and z<255:\n",
    "                            matrix[flag,count,0]=z\n",
    "                        flag+=1\n",
    "                    if id in num2:\n",
    "                        #cv2.rectangle(frame,(face[id][0]-25,face[id][1]-25),(face[id][0]+25,face[id][1]+25),(255,0,0),3)\n",
    "                        matrix[flag,count,2]=np.mean(frame[face[id][1]-25:face[id][1]+25,face[id][0]-25:face[id][0]+25,2])\n",
    "                        matrix[flag,count,1]=np.mean(frame[face[id][1]-25:face[id][1]+25,face[id][0]-25:face[id][0]+25,1])\n",
    "                        matrix[flag,count,0]=np.mean(frame[face[id][1]-25:face[id][1]+25,face[id][0]-25:face[id][0]+25,0])\n",
    "                        ####Can change the rectangluar corrdinate to select the ROI\n",
    "                        flag+=1\n",
    "        count+=1\n",
    "        flag=0\n",
    "        \n",
    "        cv2.imshow('frame',frame)#### comment this for not coming the image and can make the datasaving faster\n",
    "        key=cv2.waitKey(1)&0XFF\n",
    "        if key==ord('q'):\n",
    "            break\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56100dd5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
