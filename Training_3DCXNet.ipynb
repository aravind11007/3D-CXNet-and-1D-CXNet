{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95db4626",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch  # PyTorch main package\n",
    "import torch.nn as nn  # Neural network module from PyTorch\n",
    "import torch.nn.functional as F  # Functional API for neural networks (like activation functions)\n",
    "import pytorch_lightning as pl  # High-level framework built on top of PyTorch to automate the training loop\n",
    "from torch.utils.data import DataLoader  # DataLoader helps in batching the data for efficient training\n",
    "from Data_loader_3DCXNet import UBFC_LOADER  # Custom dataset class to load UBFC data\n",
    "import scipy  # Library for scientific and technical computing\n",
    "from scipy import signal  # Signal processing module from scipy\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint  # Callback for saving model checkpoints during training\n",
    "from pytorch_lightning.loggers import TensorBoardLogger  # Logger to send data to TensorBoard for visualization\n",
    "import numpy as np  # Library for numerical computing, handling arrays and matrices\n",
    "import matplotlib.pyplot as plt  # Plotting library for visualizing graphs and data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acd5a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def HR_FINDER(wave, fs):\n",
    "    # Perform FFT on the wave signal and extract the first 500 frequency bins (positive frequencies)\n",
    "    fftData = np.fft.fft(wave, 1000)[0:500]\n",
    "    # Generate frequency values corresponding to the FFT bins\n",
    "    hz = np.linspace(0, fs / 2, int(len(fftData)))\n",
    "    # Calculate the power spectrum by squaring the magnitude of the FFT coefficients\n",
    "    powerSpectrum = np.abs(fftData)**2\n",
    "    # Find the index of the maximum power (dominant frequency)\n",
    "    maxFreq = np.argmax(powerSpectrum)\n",
    "    # Convert the frequency (Hz) to heart rate (bpm)\n",
    "    HR = hz[maxFreq] * 60\n",
    "    # Return the calculated heart rate\n",
    "    return HR\n",
    "\n",
    "def filtering(data, fs, lowerCutoff=1, higherCutoff=3, filterOrder=5):\n",
    "    # Normalize the cutoff frequencies to the Nyquist frequency (half of the sampling rate)\n",
    "    lowerCutoffDigital = lowerCutoff / (0.5 * fs)\n",
    "    higherCutoffDigital = higherCutoff / (0.5 * fs)\n",
    "    # Design a Butterworth bandpass filter with the specified order and cutoff frequencies\n",
    "    b, a = signal.butter(filterOrder, [lowerCutoffDigital, higherCutoffDigital], btype='band', analog=False)\n",
    "    # Apply the filter to the input data using zero-phase filtering (filtfilt)\n",
    "    filtsignal = signal.filtfilt(b, a, data)\n",
    "    # Return the filtered signal\n",
    "    return filtsignal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb30f92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the training dataset\n",
    "train_path = r'D:\\Physiosens_data\\face\\train'\n",
    "\n",
    "# Define the path to the validation dataset\n",
    "val_path = r'D:\\Physiosens_data\\face\\val'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f34924",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training dataset using the UBFC_LOADER function\n",
    "train_data = UBFC_LOADER(train_path)\n",
    "\n",
    "# Load the validation dataset using the UBFC_LOADER function\n",
    "val_data = UBFC_LOADER(val_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb551f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataLoader for the training data with specified batch size, dropping the last batch if it's incomplete, and using 8 workers for parallel data loading\n",
    "train_loader = DataLoader(train_data, batch_size=10, drop_last=True, num_workers=8)\n",
    "\n",
    "# Create a DataLoader for the validation data with a batch size of 10 and using 8 workers for parallel data loading\n",
    "val_loader = DataLoader(val_data, batch_size=10, num_workers=8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f14d313",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c1022e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer_ppg(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # First 3D Convolution Layer: Extract features from the input signal (3D convolution)\n",
    "        self.cnn1 = nn.Sequential(\n",
    "            nn.Conv3d(in_channels=3, out_channels=16, kernel_size=(3, 3, 3), padding=(1, 1, 1)),  # 3D Convolution\n",
    "            nn.BatchNorm3d(16),  # Batch Normalization\n",
    "            nn.ReLU(),  # ReLU activation\n",
    "            nn.MaxPool3d(kernel_size=(1, 2, 2)),  # Max Pooling\n",
    "        )\n",
    "\n",
    "        # Second 3D Convolution Layer\n",
    "        self.cnn2 = nn.Sequential(\n",
    "            nn.Conv3d(in_channels=16, out_channels=32, kernel_size=(3, 3, 3), padding=(1, 1, 1)),  # 3D Convolution\n",
    "            nn.BatchNorm3d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool3d(kernel_size=(1, 2, 2)),  # Max Pooling\n",
    "        )\n",
    "\n",
    "        # Third 3D Convolution Layer\n",
    "        self.cnn3 = nn.Sequential(\n",
    "            nn.Conv3d(in_channels=32, out_channels=64, kernel_size=(3, 3, 3), padding=(1, 1, 1)),  # 3D Convolution\n",
    "            nn.BatchNorm3d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool3d(kernel_size=(1, 2, 2)),  # Max Pooling\n",
    "        )\n",
    "        \n",
    "        # Global Average Pooling to reduce the output to a single vector\n",
    "        self.global_pool = nn.AdaptiveAvgPool1d(output_size=(1))\n",
    "        \n",
    "        # Max Pooling for 1D signal\n",
    "        self.maxpool = nn.MaxPool1d(kernel_size=2, stride=2, padding=0)\n",
    "\n",
    "        # First 1D Convolution Block\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=1, out_channels=64, kernel_size=3, stride=1, padding=1),  # 1D Convolution\n",
    "            nn.BatchNorm1d(64),  # Batch Normalization\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1),  # Another 1D Convolution\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        # First Transformer Encoder Block (to model sequential data)\n",
    "        encoder_layer1 = nn.TransformerEncoderLayer(d_model=150, nhead=1, batch_first=True)\n",
    "        self.transformer_model1 = nn.TransformerEncoder(encoder_layer1, num_layers=2)\n",
    "\n",
    "        # Second 1D Convolution Block\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1),  # 1D Convolution\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1),  # Another 1D Convolution\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        # Second Transformer Encoder Block\n",
    "        encoder_layer2 = nn.TransformerEncoderLayer(d_model=150, nhead=1, batch_first=True)\n",
    "        self.transformer_model2 = nn.TransformerEncoder(encoder_layer2, num_layers=2)\n",
    "\n",
    "        # Third 1D Convolution Block\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1),  # 1D Convolution\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1),  # Another 1D Convolution\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        # Third Transformer Encoder Block\n",
    "        encoder_layer3 = nn.TransformerEncoderLayer(d_model=150, nhead=1, batch_first=True)\n",
    "        self.transformer_model3 = nn.TransformerEncoder(encoder_layer3, num_layers=2)\n",
    "\n",
    "        # Final 1D Convolution Layer to output the final signal\n",
    "        self.end = nn.Conv1d(in_channels=64, out_channels=1, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        # Dropout for regularization\n",
    "        self.drop_out = nn.Dropout(p=0.5)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, face):\n",
    "        # Process the face input through the CNN layers\n",
    "        forehead = self.cnn1(face)\n",
    "        forehead = self.cnn2(forehead)\n",
    "        forehead = self.cnn3(forehead)\n",
    "        \n",
    "        # Permute the dimensions for global pooling\n",
    "        forehead = forehead.permute(0, 2, 1, 3, 4)\n",
    "        b, c, _, _, _ = forehead.shape\n",
    "        forehead = forehead.reshape(b, c, -1)  # Flatten the spatial dimensions\n",
    "        forehead = self.global_pool(forehead).squeeze(-1)  # Global Average Pooling\n",
    "        forehead = forehead.unsqueeze(1)  # Add extra dimension for conv layers\n",
    "        \n",
    "        # Pass the forehead features through the first convolutional and transformer layers\n",
    "        signal = self.conv1(forehead)\n",
    "        signal = self.transformer_model1(signal)\n",
    "        signal = self.drop_out(signal)\n",
    "        signal = self.maxpool(signal)\n",
    "        signal = F.interpolate(signal, scale_factor=2)\n",
    "\n",
    "        # Pass the features through the second convolutional and transformer layers\n",
    "        signal = self.conv2(signal)\n",
    "        signal = self.drop_out(signal)\n",
    "        signal = self.transformer_model2(signal)\n",
    "        signal = self.maxpool(signal)\n",
    "        signal = F.interpolate(signal, scale_factor=2)\n",
    "\n",
    "        # Pass the features through the third convolutional and transformer layers\n",
    "        signal = self.conv3(signal)\n",
    "        signal = self.transformer_model3(signal)\n",
    "        signal = self.maxpool(signal)\n",
    "        signal = F.interpolate(signal, scale_factor=2)\n",
    "        signal = self.drop_out(signal)\n",
    "\n",
    "        # Final convolution layer to obtain the output signal\n",
    "        signal = self.end(signal)\n",
    "        \n",
    "        # Return the final output signal\n",
    "        return torch.squeeze(signal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d691ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pearson correlation loss between two signals\n",
    "def Pearson_loss(signal1, signal2):\n",
    "    # Calculate the mean of both signals\n",
    "    mean_signal1 = torch.mean(signal1)\n",
    "    mean_signal2 = torch.mean(signal2)\n",
    "    \n",
    "    # Numerator: Sum of the product of deviations of both signals from their means\n",
    "    num = torch.sum((signal1 - mean_signal1) * (signal2 - mean_signal2))\n",
    "    \n",
    "    # Denominators: Sum of the squared deviations from the mean for each signal\n",
    "    dem1 = torch.sqrt(torch.sum((signal1 - mean_signal1) ** 2))\n",
    "    dem2 = torch.sqrt(torch.sum((signal2 - mean_signal2) ** 2))\n",
    "    \n",
    "    # Pearson correlation coefficient (normalized)\n",
    "    val = num / (dem1 * dem2)\n",
    "    \n",
    "    return val\n",
    "\n",
    "# Function to compute the complete Pearson correlation loss between two sets of signals\n",
    "def Complete_Pearson(SIGNAL1, SIGNAL2):\n",
    "    loss = 0\n",
    "    \n",
    "    # Ensure both input signal sets have the same number of signals\n",
    "    assert SIGNAL1.shape[0] == SIGNAL2.shape[0], 'error: signals count mismatch'\n",
    "    \n",
    "    # Iterate over each signal pair and accumulate the Pearson loss\n",
    "    for i in range(SIGNAL1.shape[0]):\n",
    "        signal1 = SIGNAL1[i]\n",
    "        signal2 = SIGNAL2[i]\n",
    "        \n",
    "        # Add the Pearson loss for this signal pair to the total loss\n",
    "        loss += Pearson_loss(signal1, signal2)\n",
    "    \n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d68f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch Lightning model class for the transformer-based PPG model\n",
    "class Transformer_model(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Initialize the Transformer_ppg model\n",
    "        self.model = Transformer_ppg()\n",
    "        \n",
    "        # Loss function (Mean Squared Error Loss)\n",
    "        self.mse = nn.MSELoss()\n",
    "        \n",
    "        # Optimizer (Adam optimizer)\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=1e-3)\n",
    "        \n",
    "    def forward(self, face):\n",
    "        # Forward pass through the model\n",
    "        ypred = self.model(face)\n",
    "        return ypred\n",
    "    \n",
    "    def training_step(self, batch, batch_index):\n",
    "        # Get the inputs and ground truth for training\n",
    "        face, ppg = batch\n",
    "        \n",
    "        # Get the model predictions\n",
    "        ypred = self(face)\n",
    "        \n",
    "        # Calculate the loss: MSE loss and subtract Pearson loss\n",
    "        loss = self.mse(ypred, ppg) - Complete_Pearson(ypred, ppg)\n",
    "        \n",
    "        # Log the training loss\n",
    "        self.log('Training_loss', loss)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_index):\n",
    "        # Get the inputs and ground truth for validation\n",
    "        face, ppg = batch\n",
    "        \n",
    "        # Get the model predictions\n",
    "        ypred = self(face)\n",
    "        \n",
    "        # Calculate the loss: MSE loss and subtract Pearson loss\n",
    "        loss = self.mse(ypred, ppg) - Complete_Pearson(ypred, ppg)\n",
    "        \n",
    "        ytest = []\n",
    "        ground = []\n",
    "        \n",
    "        # Loop through the predictions and ground truth to calculate HR (Heart Rate)\n",
    "        for pred, LABEL in zip(ypred, ppg):\n",
    "            pred = torch.squeeze(pred)  # Remove extra dimensions\n",
    "            pred = pred.cpu().detach().numpy()  # Convert to NumPy for further processing\n",
    "            \n",
    "            # Apply signal filtering to the prediction\n",
    "            pred = filtering(data=pred, fs=30, lowerCutoff=.7, higherCutoff=3, filterOrder=5)\n",
    "            \n",
    "            # Find the heart rate from the filtered prediction\n",
    "            hr2 = HR_FINDER(pred, 30)\n",
    "            \n",
    "            # Detrend the ground truth signal and calculate its HR\n",
    "            LABEL = scipy.signal.detrend(LABEL.cpu().detach().numpy())\n",
    "            labelhr = HR_FINDER(LABEL, 30)\n",
    "            \n",
    "            # Append both predicted and ground truth HRs\n",
    "            ground.append(labelhr)\n",
    "            ytest.append(hr2)\n",
    "        \n",
    "        # Calculate Mean Absolute Error (MAE) between the predicted and ground truth HRs\n",
    "        MAE = 0\n",
    "        for i in range(len(ground)):\n",
    "            MAE += abs(ytest[i] - ground[i])\n",
    "        MAE = MAE / i\n",
    "        \n",
    "        # Log the MAE for validation\n",
    "        self.log('Val loss', MAE)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        # Return the optimizer for training\n",
    "        return [self.optimizer]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba39ca55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a ModelCheckpoint callback to save the best model based on validation loss\n",
    "checkpoint = ModelCheckpoint(\n",
    "    monitor='Val loss',  # Monitor the validation loss metric for model checkpointing\n",
    "    save_top_k=1,        # Save only the best model (with the lowest validation loss)\n",
    "    mode='min'           # Save the model when the validation loss is minimized\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2614a405",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aravind\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "model=Transformer_model()# creating a instance of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc447fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\l'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\l'\n",
      "C:\\Users\\Aravind\\AppData\\Local\\Temp\\ipykernel_1144\\1494478863.py:1: SyntaxWarning: invalid escape sequence '\\l'\n",
      "  trainer=pl.Trainer(accelerator='auto',logger=TensorBoardLogger(save_dir='.\\logs_test'),log_every_n_steps=10,\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "# Initialize the PyTorch Lightning trainer with the following settings:\n",
    "trainer = pl.Trainer(\n",
    "    accelerator='auto',  # Automatically choose the best accelerator (GPU/CPU) based on availability\n",
    "    logger=TensorBoardLogger(save_dir='.\\logs_test'),  # Use TensorBoard for logging, save logs in the './logs_test' directory\n",
    "    log_every_n_steps=10,  # Log the training progress every 10 steps\n",
    "    callbacks=checkpoint,  # Add the ModelCheckpoint callback to save the best model based on validation loss\n",
    "    max_epochs=100  # Set the maximum number of training epochs to 100\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d298cf7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 4060 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type            | Params | Mode \n",
      "--------------------------------------------------\n",
      "0 | model | Transformer_ppg | 4.4 M  | train\n",
      "1 | mse   | MSELoss         | 0      | train\n",
      "--------------------------------------------------\n",
      "4.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "4.4 M     Total params\n",
      "17.522    Total estimated model params size (MB)\n",
      "109       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f81afd40e84a40b0882a7ac72fcdc984",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                                                               | 0/? [00:00<…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aravind\\AppData\\Roaming\\Python\\Python312\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:419: Consider setting `persistent_workers=True` in 'val_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    }
   ],
   "source": [
    "# Start the training process with the following settings:\n",
    "trainer.fit(\n",
    "    model,            # The model to train (e.g., your Transformer model)\n",
    "    train_loader,     # The DataLoader for the training data\n",
    "    val_loader        # The DataLoader for the validation data\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d7b407",
   "metadata": {},
   "source": [
    "# Loading the weight of best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd559fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aravind\\AppData\\Roaming\\Python\\Python312\\site-packages\\pytorch_lightning\\utilities\\migration\\utils.py:56: The loaded checkpoint was produced with Lightning v2.5.1.post0, which is newer than your current Lightning version: v2.4.0\n",
      "C:\\Users\\Aravind\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "# Load the trained model from a checkpoint\n",
    "model = Transformer_model.load_from_checkpoint(\n",
    "    r'D:\\Lab_work\\transformer_ppg\\pycharm\\logs\\lightning_logs\\version_3\\checkpoints\\epoch=29-step=1080.ckpt',  # Path to the checkpoint file\n",
    "    map_location=torch.device('cuda')  # Load the model onto the GPU\n",
    ")\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model = model.eval()  # This switches the model to evaluation mode (disables dropout, batch norm updates, etc.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224f4dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Initialize lists to store results\n",
    "ytest = []         # List to store predicted HR values (hr2)\n",
    "ground = []        # List to store ground truth HR values\n",
    "time_req = []      # List to store the time taken for each prediction\n",
    "count = 0          # Counter for the number of samples processed\n",
    "\n",
    "# Iterate over the validation data\n",
    "for face, ppg in val_data:\n",
    "    count += 1                          # Increment the count for each sample\n",
    "    face = face.unsqueeze(0).to('cuda')  # Add batch dimension and move to GPU\n",
    "\n",
    "    # Perform prediction without tracking gradients (evaluation mode)\n",
    "    with torch.no_grad():\n",
    "        tic = time.time()  # Start the timer for measuring prediction time\n",
    "        pred = model(face)  # Make prediction\n",
    "        toc = time.time()   # End the timer after prediction\n",
    "        time_req.append(toc - tic)  # Store the time taken for this prediction\n",
    "    \n",
    "    # Process the predicted signal\n",
    "    pred = torch.squeeze(pred)  # Remove unnecessary dimensions\n",
    "    pred = pred.cpu().detach().numpy()  # Move the result back to CPU and convert to numpy\n",
    "    pred = filtering(data=pred, fs=30, lowerCutoff=.7, higherCutoff=3, filterOrder=5)  # Apply filtering\n",
    "\n",
    "    # Process the filtered signal using HeartPy to get HR\n",
    "    working_data, measures = hp.process(pred, 30)\n",
    "    hr1 = measures['bpm']  # Extract the HR value from HeartPy's measures\n",
    "    \n",
    "    # Use the custom HR_FINDER function to calculate HR from the filtered signal\n",
    "    hr2 = HR_FINDER(pred, 30)\n",
    "    HR = [hr1, hr2]  # Store both HR values\n",
    "\n",
    "    # Detrend the ground truth PPG signal and calculate HR\n",
    "    label = scipy.signal.detrend(ppg.detach().numpy())  # Remove trend from the PPG signal\n",
    "    labelhr = HR_FINDER(label, 30)  # Calculate HR from the ground truth signal\n",
    "\n",
    "    # Append ground truth and predicted HR values to the respective lists\n",
    "    ground.append(HR_FINDER(label, 30))\n",
    "    ytest.append(hr2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3d0e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FFT MAE (FFT Label): 0.9485451859825879 +/- 0.15459194275004323\n",
      "FFT RMSE (FFT Label): 2.1006766238633543 +/- 2.0123552006328307\n",
      "FFT MAPE (FFT Label): 1.0302089595994937 +/- 0.19692249313961707\n",
      "FFT Pearson (FFT Label): 0.9929127488430216 +/- 0.009869588673605907\n"
     ]
    }
   ],
   "source": [
    "predict_hr_fft_all = np.array(ytest)\n",
    "gt_hr_fft_all = np.array(ground)\n",
    "num_test_samples = len(predict_hr_fft_all)\n",
    "METRIC=[]\n",
    "for metric in ['MAE','RMSE','MAPE','Pearson', 'SNR']:\n",
    "    if metric == \"MAE\":\n",
    "        MAE_FFT = np.mean(np.abs(predict_hr_fft_all - gt_hr_fft_all))\n",
    "        standard_error = np.std(np.abs(predict_hr_fft_all - gt_hr_fft_all)) / np.sqrt(num_test_samples)\n",
    "        METRIC.append(MAE_FFT)\n",
    "        print(\"FFT MAE (FFT Label): {0} +/- {1}\".format(MAE_FFT, standard_error))\n",
    "    elif metric == \"RMSE\":\n",
    "        RMSE_FFT = np.sqrt(np.mean(np.square(predict_hr_fft_all - gt_hr_fft_all)))\n",
    "        standard_error = np.std(np.square(predict_hr_fft_all - gt_hr_fft_all)) / np.sqrt(num_test_samples)\n",
    "        print(\"FFT RMSE (FFT Label): {0} +/- {1}\".format(RMSE_FFT, standard_error))\n",
    "        METRIC.append(RMSE_FFT)\n",
    "    elif metric == \"MAPE\":\n",
    "        MAPE_FFT = np.mean(np.abs((predict_hr_fft_all - gt_hr_fft_all) / gt_hr_fft_all)) * 100\n",
    "        standard_error = np.std(np.abs((predict_hr_fft_all - gt_hr_fft_all) / gt_hr_fft_all)) / np.sqrt(num_test_samples) * 100\n",
    "        print(\"FFT MAPE (FFT Label): {0} +/- {1}\".format(MAPE_FFT, standard_error))\n",
    "        METRIC.append(MAPE_FFT)\n",
    "    elif metric == \"Pearson\":\n",
    "        Pearson_FFT = np.corrcoef(predict_hr_fft_all, gt_hr_fft_all)\n",
    "        correlation_coefficient = Pearson_FFT[0][1]\n",
    "        standard_error = np.sqrt((1 - correlation_coefficient**2) / (num_test_samples - 2))\n",
    "        METRIC.append(Pearson_FFT)\n",
    "        print(\"FFT Pearson (FFT Label): {0} +/- {1}\".format(correlation_coefficient, standard_error))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
